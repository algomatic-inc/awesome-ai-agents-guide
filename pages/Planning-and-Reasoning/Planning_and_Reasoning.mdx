# Planning and Reasoning

**Survey**

- 2023 - Valmeekam et al., On the Planning Abilities of Large Language Models: A Critical Investigation (NeurIPS) [[arXiv](https://arxiv.org/abs/2305.15771)]

- 2024.04 - Zhang et al., LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models [[arXiv](https://arxiv.org/abs/2404.01230)]
- 2024.02 - Huang et al., Understanding the planning of LLM agents: A survey [[arXiv](https://arxiv.org/abs/2402.02716)]
- 2023.12 - Sun et al., A Survey of Reasoning with Foundation Models [[arXiv](https://arxiv.org/abs/2312.11562)]
- 2023.03 - Yang et al., Foundation Models for Decision Making: Problems, Methods, and Opportunities [[arXiv](https://arxiv.org/abs/2303.04129)]

**Papers**

- 2024 - Chen et al., When is Tree Search Useful for LLM Planning? It Depends on the Discriminator (ACL) [[arXiv](https://arxiv.org/abs/2402.10890)]
- 2024 - Qiao et al., AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning (ACL) [[arXiv](https://arxiv.org/abs/2401.05268)]

- 2024 - Kim et al., An LLM Compiler for Parallel Function Calling (ICML) [[arXiv](https://arxiv.org/abs/2312.04511)]

- 2024 - Prasad et al., ADaPT: As-Needed Decomposition and Planning with Language Models (NAACL) [[arXiv](https://arxiv.org/abs/2311.05772)]
- 2024 - Zhou et al., Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning (NAACL) [[arXiv](https://arxiv.org/abs/2403.19962)]
- 2024 - Wang et al., RecMind: Large Language Model Powered Agent For Recommendation (NAACL) [[arXiv](https://arxiv.org/abs/2308.14296)]
- 2024 - Roy et al., FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs (NAACL) [[arXiv](https://arxiv.org/abs/2403.05766)]
- 2024 - Lee et al., PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers (NAACL) [[openreview](https://openreview.net/forum?id=4sajV6NEnWE)]
- 2024 - Ning et al., Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation (ICLR) [[openreview](https://openreview.net/forum?id=mqVgBbNCm9)]
- 2024 - Choi et al., LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents [[openreview](https://openreview.net/forum?id=ADSxCpCu9s)]
- 2024 - Qi et al., CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents (ICLR) [[openreview](https://openreview.net/forum?id=UBVNwD3hPN)]
- 2023 - Hao et al., Reasoning with Language Model is Planning with World Model (EMNLP) [[aclanthology](https://aclanthology.org/2023.emnlp-main.507/)]
- 2023 - Press et al., Measuring and Narrowing the Compositionality Gap in Language Models (EMNLP) [[aclanthology](https://aclanthology.org/2023.findings-emnlp.378/)]
- 2023 - Gupta et al., Visual Programming: Compositional Visual Reasoning Without Training (CVPR) [[CVF](https://openaccess.thecvf.com/content/CVPR2023/html/Gupta_Visual_Programming_Compositional_Visual_Reasoning_Without_Training_CVPR_2023_paper.html)]
- 2023 - Khot et al., Decomposed Prompting: A Modular Approach for Solving Complex Tasks (ICLR) [[openreview](https://openreview.net/forum?id=_nGgzQjzaRy)]
- 2023 - Zhou et al., Least-to-Most Prompting Enables Complex Reasoning in Large Language Models (ICLR) [[openreview](https://openreview.net/forum?id=WZH7099tgfM)]
- 2023 - Valmeekam et al., PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change (NeurIPS) [[arXiv](https://arxiv.org/abs/2206.10498)]
- 2023 - Yao et al., Tree of Thoughts: Deliberate Problem Solving with Large Language Models [[arXiv](https://arxiv.org/abs/2305.10601)]
- 2023 - Wang et al., Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (ACL) [[aclanthology](https://aclanthology.org/2023.acl-long.147/)]
- 2023 - Subramanian et al., Modular Visual Question Answering via Code Generation (ACL) [[aclanthology](https://aclanthology.org/2023.acl-short.65/)]
- 2023 - Chen et al., Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks (TMLR) [[openreview](https://openreview.net/forum?id=YfZ4ZPt8zd)] 
- 2022 - Dua et al., Successive Prompting for Decomposing Complex Questions (EMNLP) [[aclanthology](https://aclanthology.org/2022.emnlp-main.81/)]
- 2024.05 - Xu et al., Faithful Logical Reasoning via Symbolic Chain-of-Thought [[arXiv](https://arxiv.org/abs/2405.18357)]
- 2024.05 - Stechly et al., Chain of Thoughtlessness? An Analysis of CoT in Planning [[arXiv](https://arxiv.org/abs/2405.04776)]
- 2024.05 - Meta-Task Planning for Language Agents [[arXiv](https://arxiv.org/abs/2405.16510)]
- 2024.05 - Verma et al., On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models [[arXiv](https://arxiv.org/abs/2405.13966)]
- 2024.04 - Jin et al., Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs [[arXiv](https://arxiv.org/abs/2404.07103)]
- 2024.04 - Juneja et al., ùôªùôºùü∏: A Simple Society of Language Models Solves Complex Reasoning [[arXiv](https://www.arxiv.org/abs/2404.02255)]
- 2024.03 - Zhu et al., KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents [[arXiv](https://arxiv.org/abs/2403.03101)]
- 2024.02 - Hirsch et al., What's the Plan? Evaluating and Developing Planning-Aware Techniques for Language Models [[arXiv](https://arxiv.org/abs/2402.11489)]
- 2024.02 - Hu et al., Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models [[arXiv](https://arxiv.org/abs/2402.03271)]
- 2024.02 - Stechly et al., On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks [[arXiv](https://arxiv.org/abs/2402.08115)]
- 2024.02 - Kambhampati et al., LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks [[arXiv](https://arxiv.org/abs/2402.01817)]
- 2023.10 - Zhang et al., Probing the Multi-turn Planning Capabilities of LLMs via 20 Question Games [[arXiv](https://arxiv.org/abs/2310.01468)]
- 2023.10 - Wang et al., PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization [[arXiv](https://arxiv.org/abs/2310.16427)]
- 2023.08 - Besta et al., Graph of Thoughts: Solving Elaborate Problems with Large Language Models [[arXiv](https://arxiv.org/abs/2308.09687)]
- 2023.08 - Dagan et al., Dynamic Planning with a LLM [[arXiv](https://arxiv.org/abs/2308.06391)]
- 2023.05 - Sur√≠s et al., ViperGPT: Visual Inference via Python Execution for Reasoning [[arXiv](https://arxiv.org/abs/2303.08128)]
- 2023.05 - Xu et al., ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models [[arXiv](https://arxiv.org/abs/2305.18323)]
- 2023.05 - Brahman et al., PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning [[arXiv](https://arxiv.org/abs/2305.19472)]
- 2023.04 - Lu et al., Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models [[arXiv](https://arxiv.org/abs/2304.09842)]
- 2022.11 - Gao et al., PAL: Program-aided Language Models [[arXiv](https://arxiv.org/abs/2211.10435)]